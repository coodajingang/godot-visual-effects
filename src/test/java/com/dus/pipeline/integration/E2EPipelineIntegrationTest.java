package com.dus.pipeline.integration;

import com.dus.pipeline.core.Pipeline;
import com.dus.pipeline.core.SourceOperator;
import com.dus.pipeline.core.AbstractOperator;
import com.dus.pipeline.core.SinkOperator;
import com.dus.pipeline.metrics.DefaultMetricsCollector;
import com.dus.pipeline.util.TestDataFactory;
import com.dus.pipeline.util.MockDataSource;

import java.util.List;
import java.util.Map;
import java.util.ArrayList;
import java.util.concurrent.CompletableFuture;

import static org.assertj.core.api.Assertions.*;

/**
 * E2E Pipeline é›†æˆæµ‹è¯•
 * å®Œæ•´ç«¯åˆ°ç«¯æµç¨‹æµ‹è¯•
 * 
 * @author Dus
 * @version 1.0
 */
public class E2EPipelineIntegrationTest {
    
    /**
     * åœºæ™¯1ï¼šHTTP â†’ è½¬æ¢ â†’ MySQL
     * ä»æ¨¡æ‹Ÿ HTTP æ¥å£æ‹‰æ•°æ®ï¼Œè½¬æ¢å¤„ç†ï¼Œæ‰¹é‡å†™å…¥ MySQL
     */
    public static void testHttpToMySQLPipeline() throws Exception {
        System.out.println("=== E2E Test 1: HTTP â†’ è½¬æ¢ â†’ MySQL ===");
        
        // Given - æ¨¡æ‹ŸHTTPæ•°æ®æº
        SourceOperator<List<Map<String, Object>>> httpSource = MockDataSource.createMapSource(3, 5);
        
        // è½¬æ¢ç®—å­
        TransformOperator transform = new TransformOperator();
        
        // æ¨¡æ‹ŸMySQLå†™å…¥ç®—å­
        MockMySQLSinkOperator mysqlSink = new MockMySQLSinkOperator();
        
        // åˆ›å»ºç®¡é“
        DefaultMetricsCollector metrics = new DefaultMetricsCollector();
        Pipeline<List<Map<String, Object>>, Void> pipeline = new Pipeline<>(httpSource, metrics)
                .addOperator(transform)
                .addOperator(mysqlSink);
        
        // When
        pipeline.run();
        
        // Then
        assertThat(pipeline.getStatus()).isEqualTo(Pipeline.PipelineStatus.STOPPED);
        assertThat(transform.getProcessedCount()).isEqualTo(3);
        assertThat(mysqlSink.getTotalWritten()).isEqualTo(15); // 3æ‰¹æ¬¡ Ã— 5æ¡æ•°æ®
        assertThat(mysqlSink.getBatchCount()).isEqualTo(3);
        
        // éªŒè¯æ•°æ®è½¬æ¢æ­£ç¡®æ€§
        List<Map<String, Object>> writtenData = mysqlSink.getWrittenData();
        for (Map<String, Object> record : writtenData) {
            assertThat(record.containsKey("id")).isTrue();
            assertThat(record.containsKey("name")).isTrue();
            assertThat(record.containsKey("transformed")).isTrue();
            assertThat(record.get("transformed")).isEqualTo(true);
        }
        
        // æ‰“å°æŒ‡æ ‡æŠ¥å‘Š
        pipeline.printMetricsReport();
        
        System.out.println("âœ“ HTTP â†’ è½¬æ¢ â†’ MySQL æµ‹è¯•é€šè¿‡\n");
    }
    
    /**
     * åœºæ™¯2ï¼šMySQL â†’ å¯ŒåŒ– â†’ æ–‡ä»¶
     * ä» MySQL è¯»æ•°æ®ï¼Œå¤–éƒ¨ API è°ƒç”¨å¯ŒåŒ–ï¼Œå†™å…¥æ–‡ä»¶
     */
    public static void testMySQLToEnrichToFilePipeline() throws Exception {
        System.out.println("=== E2E Test 2: MySQL â†’ å¯ŒåŒ– â†’ æ–‡ä»¶ ===");
        
        // Given - æ¨¡æ‹ŸMySQLæ•°æ®æº
        SourceOperator<List<Map<String, Object>>> mysqlSource = MockDataSource.createUserSource(2, 4);
        
        // å¯ŒåŒ–ç®—å­ï¼ˆæ¨¡æ‹Ÿå¤–éƒ¨APIè°ƒç”¨ï¼‰
        EnrichOperator enrich = new EnrichOperator();
        
        // æ–‡ä»¶å†™å…¥ç®—å­
        MockFileSinkOperator fileSink = new MockFileSinkOperator("enriched_users.json");
        
        // åˆ›å»ºç®¡é“
        DefaultMetricsCollector metrics = new DefaultMetricsCollector();
        Pipeline<List<Map<String, Object>>, Void> pipeline = new Pipeline<>(mysqlSource, metrics)
                .addOperator(enrich)
                .addOperator(fileSink);
        
        // When
        pipeline.run();
        
        // Then
        assertThat(pipeline.getStatus()).isEqualTo(Pipeline.PipelineStatus.STOPPED);
        assertThat(enrich.getProcessedCount()).isEqualTo(2);
        assertThat(fileSink.getTotalWritten()).isEqualTo(8); // 2æ‰¹æ¬¡ Ã— 4æ¡æ•°æ®
        
        // éªŒè¯å¯ŒåŒ–æ•°æ®
        List<Map<String, Object>> fileContent = fileSink.getFileContent();
        for (Map<String, Object> record : fileContent) {
            assertThat(record.containsKey("enrichmentData")).isTrue();
            assertThat(record.containsKey("enrichmentTimestamp")).isTrue();
            assertThat(record.get("enriched")).isEqualTo(true);
        }
        
        // æ‰“å°æŒ‡æ ‡æŠ¥å‘Š
        pipeline.printMetricsReport();
        
        System.out.println("âœ“ MySQL â†’ å¯ŒåŒ– â†’ æ–‡ä»¶ æµ‹è¯•é€šè¿‡\n");
    }
    
    /**
     * åœºæ™¯3ï¼šå¼‚æ­¥ç®¡é“ + Metrics
     * AsyncPipeline å®Œæ•´æµç¨‹ï¼Œæ€§èƒ½æŒ‡æ ‡æ”¶é›†ï¼ŒæŠ¥å‘Šç”Ÿæˆ
     */
    public static void testAsyncPipelineWithMetrics() throws Exception {
        System.out.println("=== E2E Test 3: å¼‚æ­¥ç®¡é“ + Metrics ===");
        
        // Given - åˆ›å»ºå¼‚æ­¥ç®¡é“
        AsyncSourceOperator asyncSource = new AsyncSourceOperator(4, 3);
        AsyncTransformOperator asyncTransform = new AsyncTransformOperator();
        AsyncSinkOperator asyncSink = new AsyncSinkOperator();
        
        DefaultMetricsCollector metrics = new DefaultMetricsCollector();
        AsyncPipeline<List<Map<String, Object>>, Void> asyncPipeline = new AsyncPipeline<>(asyncSource, metrics)
                .addOperator(asyncTransform)
                .addOperator(asyncSink);
        
        // When
        CompletableFuture<Void> future = asyncPipeline.runAsync();
        future.get(); // ç­‰å¾…å®Œæˆ
        
        // Then
        assertThat(asyncPipeline.getStatus()).isEqualTo(Pipeline.PipelineStatus.STOPPED);
        assertThat(asyncTransform.getProcessedCount()).isEqualTo(4);
        assertThat(asyncSink.getTotalWritten()).isEqualTo(12); // 4æ‰¹æ¬¡ Ã— 3æ¡æ•°æ®
        
        // éªŒè¯å¼‚æ­¥å¤„ç†
        assertThat(asyncTransform.isAsyncProcessed()).isTrue();
        assertThat(asyncSink.isAsyncProcessed()).isTrue();
        
        // æ‰“å°è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡
        System.out.println("å¼‚æ­¥ç®¡é“æ€§èƒ½æŒ‡æ ‡:");
        metrics.printMetricsReport();
        
        // éªŒè¯æŒ‡æ ‡æ•°æ®
        var allMetrics = metrics.getAllMetrics();
        assertThat(allMetrics).hasSize(3); // Source + 2ä¸ªå¼‚æ­¥ç®—å­
        
        for (var operatorMetrics : allMetrics.values()) {
            assertThat(operatorMetrics.getSuccessCount()).isGreaterThan(0);
            assertThat(operatorMetrics.getFailureCount()).isEqualTo(0);
            assertThat(operatorMetrics.getTotalDurationNanos()).isGreaterThan(0);
        }
        
        System.out.println("âœ“ å¼‚æ­¥ç®¡é“ + Metrics æµ‹è¯•é€šè¿‡\n");
    }
    
    /**
     * åœºæ™¯4ï¼šé”™è¯¯å¤„ç†å’Œæ¢å¤
     * æµ‹è¯•ç®¡é“åœ¨é‡åˆ°é”™è¯¯æ—¶çš„å¤„ç†æœºåˆ¶
     */
    public static void testErrorHandlingAndRecovery() throws Exception {
        System.out.println("=== E2E Test 4: é”™è¯¯å¤„ç†å’Œæ¢å¤ ===");
        
        // Given - åˆ›å»ºä¼šå¤±è´¥çš„æ•°æ®æº
        SourceOperator<String> failingSource = MockDataSource.createFailingSource(2, 3);
        
        TransformOperator transform = new TransformOperator();
        FailingSinkOperator failingSink = new FailingSinkOperator(2); // ç¬¬2æ¬¡å†™å…¥å¤±è´¥
        
        DefaultMetricsCollector metrics = new DefaultMetricsCollector();
        Pipeline<String, Void> pipeline = new Pipeline<>(failingSource, metrics)
                .addOperator(transform)
                .addOperator(failingSink);
        
        // When & Then
        try {
            pipeline.run();
            fail("Expected pipeline to fail");
        } catch (RuntimeException e) {
            assertThat(e.getMessage()).contains("Simulated sink failure");
        }
        
        assertThat(pipeline.getStatus()).isEqualTo(Pipeline.PipelineStatus.FAILED);
        assertThat(transform.getProcessedCount()).isEqualTo(2); // åœ¨å¤±è´¥å‰å¤„ç†äº†2æ‰¹æ¬¡
        assertThat(failingSink.getCallCount()).isEqualTo(2); // è¢«è°ƒç”¨2æ¬¡
        
        // éªŒè¯é”™è¯¯æŒ‡æ ‡
        var sinkMetrics = metrics.getOperatorMetrics(failingSink.name());
        assertThat(sinkMetrics).isNotNull();
        assertThat(sinkMetrics.getFailureCount()).isEqualTo(1);
        
        System.out.println("âœ“ é”™è¯¯å¤„ç†å’Œæ¢å¤ æµ‹è¯•é€šè¿‡\n");
    }
    
    /**
     * åœºæ™¯5ï¼šå¤§æ•°æ®é‡æ€§èƒ½æµ‹è¯•
     * æµ‹è¯•ç®¡é“å¤„ç†å¤§æ•°æ®é‡æ—¶çš„æ€§èƒ½è¡¨ç°
     */
    public static void testLargeDataVolumePerformance() throws Exception {
        System.out.println("=== E2E Test 5: å¤§æ•°æ®é‡æ€§èƒ½æµ‹è¯• ===");
        
        // Given - å¤§æ•°æ®é‡æµ‹è¯•
        int totalRecords = 10000;
        int batchSize = 100;
        int batchCount = totalRecords / batchSize;
        
        SourceOperator<List<Map<String, Object>>> largeDataSource = MockDataSource.createMapSource(batchCount, batchSize);
        
        PerformanceTestOperator perfOperator = new PerformanceTestOperator();
        MockFileSinkOperator fileSink = new MockFileSinkOperator("large_data_output.json");
        
        DefaultMetricsCollector metrics = new DefaultMetricsCollector();
        Pipeline<List<Map<String, Object>>, Void> pipeline = new Pipeline<>(largeDataSource, metrics)
                .addOperator(perfOperator)
                .addOperator(fileSink);
        
        // When
        long startTime = System.currentTimeMillis();
        pipeline.run();
        long endTime = System.currentTimeMillis();
        
        // Then
        assertThat(pipeline.getStatus()).isEqualTo(Pipeline.PipelineStatus.STOPPED);
        assertThat(perfOperator.getProcessedCount()).isEqualTo(batchCount);
        assertThat(fileSink.getTotalWritten()).isEqualTo(totalRecords);
        
        long duration = endTime - startTime;
        double throughput = (double) totalRecords / duration * 1000; // records per second
        
        System.out.println("æ€§èƒ½æµ‹è¯•ç»“æœ:");
        System.out.println("- æ€»è®°å½•æ•°: " + totalRecords);
        System.out.println("- å¤„ç†æ—¶é—´: " + duration + "ms");
        System.out.println("- ååé‡: " + String.format("%.2f", throughput) + " records/sec");
        
        // æ‰“å°æ€§èƒ½æŒ‡æ ‡
        pipeline.printMetricsReport();
        
        System.out.println("âœ“ å¤§æ•°æ®é‡æ€§èƒ½æµ‹è¯•é€šè¿‡\n");
    }
    
    /**
     * è¿è¡Œæ‰€æœ‰E2Eæµ‹è¯•
     */
    public static void runAllTests() {
        try {
            testHttpToMySQLPipeline();
            testMySQLToEnrichToFilePipeline();
            testAsyncPipelineWithMetrics();
            testErrorHandlingAndRecovery();
            testLargeDataVolumePerformance();
            
            System.out.println("ğŸ‰ æ‰€æœ‰E2Eé›†æˆæµ‹è¯•é€šè¿‡ï¼");
            
        } catch (Exception e) {
            System.err.println("âŒ E2Eæµ‹è¯•å¤±è´¥: " + e.getMessage());
            e.printStackTrace();
        }
    }
    
    // æµ‹è¯•è¾…åŠ©ç±»
    
    private static class TransformOperator extends AbstractOperator<List<Map<String, Object>>, List<Map<String, Object>>> {
        private int processedCount = 0;
        
        @Override
        protected List<Map<String, Object>> doProcess(List<Map<String, Object>> input) throws Exception {
            processedCount++;
            
            List<Map<String, Object>> transformed = new ArrayList<>();
            for (Map<String, Object> record : input) {
                Map<String, Object> newRecord = new java.util.HashMap<>(record);
                newRecord.put("transformed", true);
                newRecord.put("transformTimestamp", System.currentTimeMillis());
                transformed.add(newRecord);
            }
            
            return transformed;
        }
        
        public int getProcessedCount() { return processedCount; }
    }
    
    private static class MockMySQLSinkOperator extends SinkOperator<List<Map<String, Object>>> {
        private int totalWritten = 0;
        private int batchCount = 0;
        private List<Map<String, Object>> writtenData = new ArrayList<>();
        
        @Override
        protected void write(List<Map<String, Object>> input) throws Exception {
            if (input != null) {
                totalWritten += input.size();
                batchCount++;
                writtenData.addAll(input);
            }
        }
        
        public int getTotalWritten() { return totalWritten; }
        public int getBatchCount() { return batchCount; }
        public List<Map<String, Object>> getWrittenData() { return new ArrayList<>(writtenData); }
    }
    
    private static class EnrichOperator extends AbstractOperator<List<Map<String, Object>>, List<Map<String, Object>>> {
        private int processedCount = 0;
        
        @Override
        protected List<Map<String, Object>> doProcess(List<Map<String, Object>> input) throws Exception {
            processedCount++;
            
            List<Map<String, Object>> enriched = new ArrayList<>();
            for (Map<String, Object> record : input) {
                Map<String, Object> enrichedRecord = new java.util.HashMap<>(record);
                
                // æ¨¡æ‹Ÿå¤–éƒ¨APIè°ƒç”¨å¯ŒåŒ–
                Map<String, Object> enrichmentData = new java.util.HashMap<>();
                enrichmentData.put("source", "external_api");
                enrichmentData.put("version", "1.0");
                enrichmentData.put("additionalInfo", "Enriched at " + System.currentTimeMillis());
                
                enrichedRecord.put("enrichmentData", enrichmentData);
                enrichedRecord.put("enrichmentTimestamp", System.currentTimeMillis());
                enrichedRecord.put("enriched", true);
                
                enriched.add(enrichedRecord);
            }
            
            return enriched;
        }
        
        public int getProcessedCount() { return processedCount; }
    }
    
    private static class MockFileSinkOperator extends SinkOperator<List<Map<String, Object>>> {
        private final String filename;
        private int totalWritten = 0;
        private List<Map<String, Object>> fileContent = new ArrayList<>();
        
        public MockFileSinkOperator(String filename) {
            this.filename = filename;
        }
        
        @Override
        protected void write(List<Map<String, Object>> input) throws Exception {
            if (input != null) {
                totalWritten += input.size();
                fileContent.addAll(input);
                System.out.println("å†™å…¥æ–‡ä»¶ " + filename + ": " + input.size() + " æ¡è®°å½•");
            }
        }
        
        public int getTotalWritten() { return totalWritten; }
        public List<Map<String, Object>> getFileContent() { return new ArrayList<>(fileContent); }
    }
    
    private static class AsyncSourceOperator extends com.dus.pipeline.async.AsyncSourceOperator<List<Map<String, Object>>> {
        private final int maxBatches;
        private final int batchSize;
        private int currentBatch = 0;
        
        public AsyncSourceOperator(int maxBatches, int batchSize) {
            this.maxBatches = maxBatches;
            this.batchSize = batchSize;
        }
        
        @Override
        protected java.util.concurrent.CompletableFuture<List<Map<String, Object>>> doNextBatchAsync() {
            return java.util.concurrent.CompletableFuture.supplyAsync(() -> {
                try {
                    Thread.sleep(10); // æ¨¡æ‹Ÿå¼‚æ­¥å»¶è¿Ÿ
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                
                if (currentBatch >= maxBatches) {
                    return null;
                }
                
                List<Map<String, Object>> batch = TestDataFactory.createMapList(batchSize);
                for (Map<String, Object> item : batch) {
                    item.put("asyncBatchId", currentBatch);
                }
                
                currentBatch++;
                return batch;
            });
        }
    }
    
    private static class AsyncTransformOperator extends com.dus.pipeline.async.AsyncOperator<List<Map<String, Object>>, List<Map<String, Object>>> {
        private int processedCount = 0;
        private boolean asyncProcessed = false;
        
        @Override
        protected java.util.concurrent.CompletableFuture<List<Map<String, Object>>> processAsync(List<Map<String, Object>> input) {
            return java.util.concurrent.CompletableFuture.supplyAsync(() -> {
                try {
                    Thread.sleep(20); // æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                
                processedCount++;
                asyncProcessed = true;
                
                List<Map<String, Object>> transformed = new ArrayList<>();
                for (Map<String, Object> record : input) {
                    Map<String, Object> newRecord = new java.util.HashMap<>(record);
                    newRecord.put("asyncTransformed", true);
                    transformed.add(newRecord);
                }
                
                return transformed;
            });
        }
        
        public int getProcessedCount() { return processedCount; }
        public boolean isAsyncProcessed() { return asyncProcessed; }
    }
    
    private static class AsyncSinkOperator extends com.dus.pipeline.async.AsyncOperator<List<Map<String, Object>>, Void> {
        private int totalWritten = 0;
        private boolean asyncProcessed = false;
        
        @Override
        protected java.util.concurrent.CompletableFuture<Void> processAsync(List<Map<String, Object>> input) {
            return java.util.concurrent.CompletableFuture.runAsync(() -> {
                try {
                    Thread.sleep(15); // æ¨¡æ‹Ÿå¼‚æ­¥å†™å…¥
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                
                if (input != null) {
                    totalWritten += input.size();
                }
                asyncProcessed = true;
            });
        }
        
        public int getTotalWritten() { return totalWritten; }
        public boolean isAsyncProcessed() { return asyncProcessed; }
    }
    
    private static class FailingSinkOperator extends SinkOperator<String> {
        private final int failAfterCalls;
        private int callCount = 0;
        
        public FailingSinkOperator(int failAfterCalls) {
            this.failAfterCalls = failAfterCalls;
        }
        
        @Override
        protected void write(String input) throws Exception {
            callCount++;
            if (callCount >= failAfterCalls) {
                throw new RuntimeException("Simulated sink failure");
            }
        }
        
        public int getCallCount() { return callCount; }
    }
    
    private static class PerformanceTestOperator extends AbstractOperator<List<Map<String, Object>>, List<Map<String, Object>>> {
        private int processedCount = 0;
        
        @Override
        protected List<Map<String, Object>> doProcess(List<Map<String, Object>> input) throws Exception {
            processedCount++;
            
            // æ¨¡æ‹Ÿä¸€äº›CPUå¯†é›†å‹å¤„ç†
            List<Map<String, Object>> processed = new ArrayList<>();
            for (Map<String, Object> record : input) {
                Map<String, Object> newRecord = new java.util.HashMap<>(record);
                
                // æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
                double sum = 0;
                for (int i = 0; i < 100; i++) {
                    sum += Math.sin(i) * Math.cos(i);
                }
                newRecord.put("computedValue", sum);
                
                processed.add(newRecord);
            }
            
            return processed;
        }
        
        public int getProcessedCount() { return processedCount; }
    }
}